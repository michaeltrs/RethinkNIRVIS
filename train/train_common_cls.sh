#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ1of10_commonembed  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA1of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_OULU-CASIA_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_BUAA_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ2of10_commonembed    | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA2of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ3of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA3of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ4of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA4of10_commonembed  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ5of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA5of10_commonembed  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ6of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA6of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ7of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA7of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ8of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA8of10_commonembed    | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ9of10_commonembed | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA9of10_commonembed  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_LAMP-HQ10of10_commonembed  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config config_iresnet18_WF600k_CASIA10of10_commonembed  | tee hist.log
#
##python3 -m torch.distributed.launch --nproc_per_node=7 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_embed_rgb-cls.py --config config_iresnet18_WF600k_LAMP-HQ1of10_commonembed  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_feat-predict_rgb-cls.py | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr="127.0.0.3" --master_port=1235 train_feat-predict_rgb-cls_end2end.py | tee hist.log

#-----------------------------------------------------------------------------------------------------------------------

#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_LAMP-HQ1of10_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_CASIA1of10_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_BUAA_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_OULU-CASIA_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet50_init-WF600k_LAMP-HQ1of10_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet50_init-WF600k_CASIA1of10_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet50_init-WF600k_BUAA_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet50_init-WF600k_OULU-CASIA_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet100_init-WF600k_LAMP-HQ1of10_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet100_init-WF600k_CASIA1of10_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet100_init-WF600k_BUAA_common-cls  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet100_init-WF600k_OULU-CASIA_common-cls  | tee hist.log


##-----------------------------------------------------------------------------------------------------------------------
## common cls with update buffers
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_LAMP-HQ1of10_common-cls_bn  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet50_init-WF600k_LAMP-HQ1of10_common-cls_bn  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet100_init-WF600k_LAMP-HQ1of10_common-cls_bn  | tee hist.log
#
## common cls with smaller lr
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_LAMP-HQ1of10_common-cls_lr1e5  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet50_init-WF600k_LAMP-HQ1of10_common-cls_lr1e5  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet100_init-WF600k_LAMP-HQ1of10_common-cls_lr1e5  | tee hist.log
#
## naive finetune with batch norm
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls_vis-predict-detach.py --config iresnet18_init-WF600k_LAMP-HQ1of10_common-cls  | tee hist.log
#
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandRed_LAMP-HQ1of10_common-cls_bn  | tee hist.log
#
#python3 -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandColor_LAMP-HQ1of10_common-cls_bn  | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandRed_LAMP-HQ1of10_common-cls_bn  | tee hist.log
python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_CASIA1of10_common-cls_bn  | tee hist.log
python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_OULU-CASIA_common-cls_bn  | tee hist.log
python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k_BUUA_common-cls_bn  | tee hist.log
python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandRed_BUUA_common-cls_bn | tee hist.log
#python3 -m torch.distributed.launch --nproc_per_node=8 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandRed_CASIA1of10_common-cls_bn  | tee hist.log
python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandRed_OULU-CASIA_common-cls_bn  | tee hist.log
python3 -m torch.distributed.launch --nproc_per_node=6 --nnodes=1 --node_rank=0 --master_addr="127.0.0.2" --master_port=1234 train_common_cls.py --config iresnet18_init-WF600k-RandRed_LAMP-HQ1of10_common-cls_bn  | tee hist.log

